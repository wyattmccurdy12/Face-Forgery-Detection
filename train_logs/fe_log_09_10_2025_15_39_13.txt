EPOCH 1: 
batch 1000 loss: 0.05537804851680994
batch 2000 loss: 0.01878755476360675
batch 3000 loss: 0.01124801865973859
batch 4000 loss: 0.008134477990417508
batch 5000 loss: 0.005827028881969455
batch 6000 loss: 0.006457257576767006
LOSS train 0.006457257576767006 valid 0.01523883081972599 
EPOCH 2: 
batch 1000 loss: 0.002021989480779666
batch 2000 loss: 0.0013754434516413312
batch 3000 loss: 0.0018947196888857434
batch 4000 loss: 0.0025367962452928624
batch 5000 loss: 0.0020392474334357757
batch 6000 loss: 0.0017442888348941778
LOSS train 0.0017442888348941778 valid 0.012703925371170044 
EPOCH 3: 
batch 1000 loss: 0.0007843111674173997
batch 2000 loss: 0.0003018598701992232
batch 3000 loss: 0.0003895015818889078
batch 4000 loss: 0.0007113831937340365
batch 5000 loss: 0.0008684620165895467
batch 6000 loss: 0.000798873733954224
LOSS train 0.000798873733954224 valid 0.00957880076020956 
EPOCH 4: 
batch 1000 loss: 0.0004653642728248997
batch 2000 loss: 0.0003643785059148286
batch 3000 loss: 0.00030292900495442154
batch 4000 loss: 0.0004365430934883534
batch 5000 loss: 0.00048046992226022665
batch 6000 loss: 0.0007348930764699161
LOSS train 0.0007348930764699161 valid 0.010581535287201405 
EPOCH 5: 
batch 1000 loss: 0.00101537732941415
batch 2000 loss: 0.000272836432422082
batch 3000 loss: 0.0008983549532699726
batch 4000 loss: 0.0007771396342363914
batch 5000 loss: 0.0003270412395236235
batch 6000 loss: 0.0004711120695869795
LOSS train 0.0004711120695869795 valid 0.012263785116374493 
EPOCH 6: 
batch 1000 loss: 0.00031494468874097945
batch 2000 loss: 0.00020958712740798546
batch 3000 loss: 0.00032699557226965225
batch 4000 loss: 0.0003904560361729637
batch 5000 loss: 0.00018434617324714964
batch 6000 loss: 0.0001262733461442167
LOSS train 0.0001262733461442167 valid 0.009490486234426498 
EPOCH 7: 
batch 1000 loss: 7.699213320779564e-05
batch 2000 loss: 5.990901212055633e-05
batch 3000 loss: 6.004573786970013e-05
batch 4000 loss: 4.5153471162620915e-05
batch 5000 loss: 7.75439060911367e-05
batch 6000 loss: 4.671192048272132e-05
LOSS train 4.671192048272132e-05 valid 0.01649961806833744 
EPOCH 8: 
batch 1000 loss: 0.0031368718732746855
batch 2000 loss: 0.000988049701694763
batch 3000 loss: 0.0004432601812977737
batch 4000 loss: 0.00016786530345166284
batch 5000 loss: 0.00013463654631937062
batch 6000 loss: 0.0001194039679362504
LOSS train 0.0001194039679362504 valid 0.01260688528418541 
EPOCH 9: 
batch 1000 loss: 0.0002640887771343614
batch 2000 loss: 0.00017777449330958462
batch 3000 loss: 0.00010027813133285691
batch 4000 loss: 5.524826117880366e-05
batch 5000 loss: 5.5520001809441056e-05
batch 6000 loss: 5.397503477752252e-05
LOSS train 5.397503477752252e-05 valid 0.008488244377076626 
EPOCH 10: 
batch 1000 loss: 3.539786496918396e-05
batch 2000 loss: 3.074063208185862e-05
batch 3000 loss: 3.5899952962154205e-05
batch 4000 loss: 3.481534787260898e-05
batch 5000 loss: 4.2519337451722094e-05
batch 6000 loss: 2.240109941561741e-05
LOSS train 2.240109941561741e-05 valid 0.00904681533575058 
EPOCH 11: 
batch 1000 loss: 3.6929442420046147e-05
batch 2000 loss: 3.9438840503351005e-05
batch 3000 loss: 6.80278752578829e-05
batch 4000 loss: 3.431585853076058e-05
batch 5000 loss: 4.473335915275811e-05
batch 6000 loss: 4.016179594964342e-05
LOSS train 4.016179594964342e-05 valid 0.00907206628471613 
EPOCH 12: 
batch 1000 loss: 2.958203185522734e-05
batch 2000 loss: 1.755818327552561e-05
batch 3000 loss: 0.0001657814606956549
batch 4000 loss: 2.5928482794427056e-05
batch 5000 loss: 2.4426964459905775e-05
batch 6000 loss: 0.00016210498254855566
LOSS train 0.00016210498254855566 valid 0.00867617130279541 
EPOCH 13: 
batch 1000 loss: 0.000156263698264695
batch 2000 loss: 0.00010546963794388376
batch 3000 loss: 0.0005061402112352198
batch 4000 loss: 0.00019037881853967064
batch 5000 loss: 0.00021887024951905686
batch 6000 loss: 9.893065076335006e-05
LOSS train 9.893065076335006e-05 valid 0.026797961443662643 
EPOCH 14: 
batch 1000 loss: 7.103199332522082e-05
batch 2000 loss: 0.0007896439886790176
batch 3000 loss: 7.65776125958837e-05
batch 4000 loss: 0.00017590083366474118
batch 5000 loss: 7.707901006222074e-05
batch 6000 loss: 7.101039399407227e-05
LOSS train 7.101039399407227e-05 valid 0.021893825381994247 
EPOCH 15: 
batch 1000 loss: 0.0005335574994368244
batch 2000 loss: 0.00011675287644396803
batch 3000 loss: 0.000500560174242537
batch 4000 loss: 0.0001232238476337102
batch 5000 loss: 2.8687976765183975e-05
batch 6000 loss: 6.232482724391276e-05
LOSS train 6.232482724391276e-05 valid 0.010588161647319794 
EPOCH 16: 
batch 1000 loss: 9.798246446030134e-05
batch 2000 loss: 3.0339423119130514e-05
batch 3000 loss: 1.8538340177201462e-05
batch 4000 loss: 2.0856547575760943e-05
batch 5000 loss: 2.0727047177985016e-05
batch 6000 loss: 0.00021236796397363378
LOSS train 0.00021236796397363378 valid 0.01620524562895298 
EPOCH 17: 
batch 1000 loss: 3.546499011159199e-05
batch 2000 loss: 0.00017117038527703697
batch 3000 loss: 0.00025715254342037496
batch 4000 loss: 2.6789505373699286e-05
batch 5000 loss: 8.618417973048054e-05
batch 6000 loss: 3.8832809210305186e-05
LOSS train 3.8832809210305186e-05 valid 0.006759567651897669 
EPOCH 18: 
batch 1000 loss: 1.362459423700102e-05
batch 2000 loss: 1.4075450905124853e-05
batch 3000 loss: 2.0519334610298756e-05
batch 4000 loss: 1.8117656440040264e-05
batch 5000 loss: 1.3273980006147212e-05
batch 6000 loss: 8.856783629653364e-06
LOSS train 8.856783629653364e-06 valid 0.008749785833060741 
EPOCH 19: 
batch 1000 loss: 2.1610927080359944e-05
batch 2000 loss: 1.1185671996116752e-05
batch 3000 loss: 1.980917376221214e-05
batch 4000 loss: 1.2075919238839106e-05
batch 5000 loss: 9.663857859607105e-06
batch 6000 loss: 6.367320249268005e-06
LOSS train 6.367320249268005e-06 valid 0.007037901319563389 
EPOCH 20: 
batch 1000 loss: 1.050410721072126e-05
batch 2000 loss: 1.9622972440458852e-05
batch 3000 loss: 7.36472633374774e-06
batch 4000 loss: 1.0217796817840963e-05
batch 5000 loss: 5.1422337151365125e-05
batch 6000 loss: 5.511102985664706e-05
LOSS train 5.511102985664706e-05 valid 0.007657120935618877 
EPOCH 21: 
batch 1000 loss: 2.2889375179545367e-05
batch 2000 loss: 3.8764309242822034e-05
batch 3000 loss: 2.2097090933385742e-05
batch 4000 loss: 1.4631054996357308e-05
batch 5000 loss: 1.4625717100699376e-05
batch 6000 loss: 8.284344362238016e-06
LOSS train 8.284344362238016e-06 valid 0.008253010921180248 
EPOCH 22: 
batch 1000 loss: 6.369756726542164e-06
batch 2000 loss: 9.426001116054295e-06
batch 3000 loss: 7.461030950963732e-06
batch 4000 loss: 7.4286583182754385e-06
batch 5000 loss: 1.5969563765708015e-05
batch 6000 loss: 5.930544962126305e-06
LOSS train 5.930544962126305e-06 valid 0.008715291507542133 
EPOCH 23: 
batch 1000 loss: 4.564098480997814e-06
batch 2000 loss: 5.872470075701131e-06
batch 3000 loss: 1.8139036720498326e-05
batch 4000 loss: 1.1001410677920377e-05
batch 5000 loss: 5.4814232898081624e-06
batch 6000 loss: 6.448032515208979e-06
LOSS train 6.448032515208979e-06 valid 0.01131029799580574 
EPOCH 24: 
batch 1000 loss: 8.35873232171025e-06
batch 2000 loss: 6.0709616737710805e-06
batch 3000 loss: 6.196941621681163e-06
batch 4000 loss: 5.362427173906781e-06
batch 5000 loss: 6.5642020655474196e-06
batch 6000 loss: 6.904588963749347e-06
LOSS train 6.904588963749347e-06 valid 0.00905232410877943 
EPOCH 25: 
batch 1000 loss: 7.3443784305453616e-06
batch 2000 loss: 4.123404788543894e-06
batch 3000 loss: 9.17029940679015e-06
batch 4000 loss: 6.572992616838746e-06
batch 5000 loss: 6.290816762543727e-06
batch 6000 loss: 4.583983999438601e-06
LOSS train 4.583983999438601e-06 valid 0.0074288006871938705 
EPOCH 26: 
batch 1000 loss: 4.784915901979048e-06
batch 2000 loss: 5.115402783189893e-06
batch 3000 loss: 5.761560260722831e-06
batch 4000 loss: 4.331756816810639e-06
batch 5000 loss: 5.371715809459943e-06
batch 6000 loss: 0.00019194313053802147
LOSS train 0.00019194313053802147 valid 0.0425274558365345 
EPOCH 27: 
batch 1000 loss: 0.0003903716174222609
batch 2000 loss: 0.00015306511072793683
batch 3000 loss: 0.00029579605627480987
batch 4000 loss: 0.0005508244074885908
batch 5000 loss: 8.214710142104308e-05
batch 6000 loss: 9.655080456019505e-05
LOSS train 9.655080456019505e-05 valid 0.010547910816967487 
EPOCH 28: 
batch 1000 loss: 1.6910782727705963e-05
batch 2000 loss: 1.5656191895828895e-05
batch 3000 loss: 1.8825383848877664e-05
batch 4000 loss: 9.381724048978412e-06
batch 5000 loss: 1.6310531137804675e-05
batch 6000 loss: 9.603760164168307e-06
LOSS train 9.603760164168307e-06 valid 0.008642257191240788 
EPOCH 29: 
batch 1000 loss: 8.023095527789791e-06
batch 2000 loss: 9.353415529631093e-06
batch 3000 loss: 6.877648228226008e-06
batch 4000 loss: 8.612255796464297e-06
batch 5000 loss: 6.460679358809784e-06
batch 6000 loss: 6.981560024257761e-06
LOSS train 6.981560024257761e-06 valid 0.006733679678291082 
EPOCH 30: 
batch 1000 loss: 1.0092609878114445e-05
batch 2000 loss: 7.069355746239126e-06
batch 3000 loss: 6.5333304247872096e-06
batch 4000 loss: 9.43100499944194e-06
batch 5000 loss: 1.304674059819888e-05
batch 6000 loss: 1.505316745110008e-05
LOSS train 1.505316745110008e-05 valid 0.007205712143331766 
EPOCH 31: 
batch 1000 loss: 7.445273543439157e-06
batch 2000 loss: 8.056583472395574e-06
batch 3000 loss: 6.218428804089627e-06
batch 4000 loss: 9.336509716163732e-06
batch 5000 loss: 8.489282750886674e-06
batch 6000 loss: 5.050224927316549e-06
LOSS train 5.050224927316549e-06 valid 0.006360027007758617 
EPOCH 32: 
batch 1000 loss: 5.290173157192158e-06
batch 2000 loss: 5.090913680803055e-06
batch 3000 loss: 8.106972383828293e-06
batch 4000 loss: 5.64796370123588e-06
batch 5000 loss: 8.907547092462665e-06
batch 6000 loss: 5.781466187443129e-06
LOSS train 5.781466187443129e-06 valid 0.007403483148664236 
EPOCH 33: 
batch 1000 loss: 4.673696659580173e-06
batch 2000 loss: 4.578499605173647e-06
batch 3000 loss: 4.25296904538186e-06
batch 4000 loss: 4.6776005139577134e-06
batch 5000 loss: 7.923729553169778e-06
batch 6000 loss: 4.970894112759083e-06
LOSS train 4.970894112759083e-06 valid 0.006736899726092815 
EPOCH 34: 
batch 1000 loss: 6.114219760902983e-06
batch 2000 loss: 4.356983891227628e-06
batch 3000 loss: 3.956194324189255e-06
batch 4000 loss: 3.951506387792847e-06
batch 5000 loss: 3.6712157885432363e-06
batch 6000 loss: 5.138826994837586e-06
LOSS train 5.138826994837586e-06 valid 0.00907212309539318 
EPOCH 35: 
batch 1000 loss: 0.005066820443513052
batch 2000 loss: 0.001015776925446744
batch 3000 loss: 0.0005745466194451864
batch 4000 loss: 0.0005459834623336519
batch 5000 loss: 0.00042667256039027277
batch 6000 loss: 0.0002901255748089966
LOSS train 0.0002901255748089966 valid 0.007309578824788332 
EPOCH 36: 
batch 1000 loss: 0.00018839137524037143
batch 2000 loss: 0.00011586572236257098
batch 3000 loss: 3.8640309165074885e-05
batch 4000 loss: 4.07679190823842e-05
batch 5000 loss: 4.772927243521963e-05
batch 6000 loss: 1.7827644820073375e-05
LOSS train 1.7827644820073375e-05 valid 0.006154444068670273 
EPOCH 37: 
